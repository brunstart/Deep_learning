{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"[과제] 역전파 이용한 다층 신경망 만들기.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNDL1SEOF82f9A9arWKepEr"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"ZKtAhkm4J2Z3","executionInfo":{"status":"ok","timestamp":1601896240625,"user_tz":-540,"elapsed":880,"user":{"displayName":"Seung min Yang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggh6p0khXlZ7IJRTGo-8JTqKaaHhMlpE2ET1kqtYQ=s64","userId":"01177916219728503153"}}},"source":["import tensorflow as tf\n","import numpy as np\n","import matplotlib.pyplot as plt\n","plt.style.use(['seaborn-whitegrid'])\n","from collections import OrderedDict"],"execution_count":77,"outputs":[]},{"cell_type":"code","metadata":{"id":"S3SQq80sJ8mR","executionInfo":{"status":"ok","timestamp":1601896240995,"user_tz":-540,"elapsed":856,"user":{"displayName":"Seung min Yang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggh6p0khXlZ7IJRTGo-8JTqKaaHhMlpE2ET1kqtYQ=s64","userId":"01177916219728503153"}}},"source":["np.random.seed(42)\n","\n","mnist = tf.keras.datasets.mnist\n","\n","(X_train, y_train), (X_test, y_test) = mnist.load_data()\n","\n","num_classes = 10"],"execution_count":78,"outputs":[]},{"cell_type":"code","metadata":{"id":"B95lI86tKIyY","executionInfo":{"status":"ok","timestamp":1601896240996,"user_tz":-540,"elapsed":523,"user":{"displayName":"Seung min Yang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggh6p0khXlZ7IJRTGo-8JTqKaaHhMlpE2ET1kqtYQ=s64","userId":"01177916219728503153"}}},"source":["X_train, X_test = X_train.reshape(-1, 28 * 28).astype(np.float32), X_test.reshape(-1, 28*28).astype(np.float32)\n","\n","X_train /= .255\n","X_test /= .255\n","\n","y_train = np.eye(num_classes)[y_train]"],"execution_count":79,"outputs":[]},{"cell_type":"code","metadata":{"id":"ar7DZIlMKLjJ","executionInfo":{"status":"ok","timestamp":1601896241677,"user_tz":-540,"elapsed":793,"user":{"displayName":"Seung min Yang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggh6p0khXlZ7IJRTGo-8JTqKaaHhMlpE2ET1kqtYQ=s64","userId":"01177916219728503153"}},"outputId":"a4d6954d-054b-4fb7-cf4f-161f68de9e35","colab":{"base_uri":"https://localhost:8080/","height":89}},"source":["print(X_train.shape)\n","print(y_train.shape)\n","print(X_test.shape)\n","print(y_test.shape)"],"execution_count":80,"outputs":[{"output_type":"stream","text":["(60000, 784)\n","(60000, 10)\n","(10000, 784)\n","(10000,)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"rFeXORJjKM7s","executionInfo":{"status":"ok","timestamp":1601896241991,"user_tz":-540,"elapsed":757,"user":{"displayName":"Seung min Yang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggh6p0khXlZ7IJRTGo-8JTqKaaHhMlpE2ET1kqtYQ=s64","userId":"01177916219728503153"}}},"source":["epochs = 1000\n","learning_rate = 1e-3\n","batch_size = 100\n","train_size = X_train.shape[0]"],"execution_count":81,"outputs":[]},{"cell_type":"code","metadata":{"id":"8E2_fN1dKRzv","executionInfo":{"status":"ok","timestamp":1601896242334,"user_tz":-540,"elapsed":746,"user":{"displayName":"Seung min Yang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggh6p0khXlZ7IJRTGo-8JTqKaaHhMlpE2ET1kqtYQ=s64","userId":"01177916219728503153"}}},"source":["def softmax(x):\n","  if x.ndim == 2:\n","    x = x.T\n","    x = x - np.max(x, axis = 0)\n","    y = np.exp(x) / np.sum(np.exp(x), axis=0)\n","    return y.T\n","\n","  x=  x - np.max(x)\n","  return np.exp(x) / np.sum(xp.exp(x))\n","\n","def mean_squared_error(pred_y, true_y):\n","  return 0.5 * np.sum((pred_y -true_y) **2)\n","\n","def cross_entropy_error(pred_y, true_y):\n","  if pred_y.ndim == 1:\n","    true_y = true_y.reshape(1, true_y.size)\n","    pred_y  = pred_y.reshape(1, pred_y.size)\n","\n","  if true_y.size == pred_y.size:\n","    true_y = true_y.argmax(axis=1)\n","  \n","  batch_size = pred_y.shape[0]\n","  return -np.sum(np.log(pred_y[np.arange(batch_size), true_y] + 1e-7)) / batch_size\n","\n","def softmax_loss(X, true):\n","  pred_y = softmax(X)\n","  return cross_entropy_error(pred_y, true_y)"],"execution_count":82,"outputs":[]},{"cell_type":"code","metadata":{"id":"ej2m6Robs-uJ","executionInfo":{"status":"ok","timestamp":1601896242695,"user_tz":-540,"elapsed":801,"user":{"displayName":"Seung min Yang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggh6p0khXlZ7IJRTGo-8JTqKaaHhMlpE2ET1kqtYQ=s64","userId":"01177916219728503153"}}},"source":["class ReLU():\n","  def __init__(self):\n","    self.out = None\n","  \n","  def forward(self, x):\n","    self.mask = (x < 0)\n","    out = x.copy()\n","    out[x<0] = 0\n","    return out\n","\n","  def backward(self, dout):\n","    dout[self.mask] = 0\n","    dx = dout\n","    return dx"],"execution_count":83,"outputs":[]},{"cell_type":"code","metadata":{"id":"TWoPmtpNtZ__","executionInfo":{"status":"ok","timestamp":1601896242695,"user_tz":-540,"elapsed":517,"user":{"displayName":"Seung min Yang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggh6p0khXlZ7IJRTGo-8JTqKaaHhMlpE2ET1kqtYQ=s64","userId":"01177916219728503153"}}},"source":["class Sigmoid():\n","\n","  def __init__(self):\n","    self.out = None\n","  \n","  def forward(self, x):\n","    out = 1 / (1 + np.exp(-x))\n","    return out\n","\n","  def backward(self, dout):\n","    dx = dout * (1.0 - self.out) * self.dout\n","    return dx"],"execution_count":84,"outputs":[]},{"cell_type":"code","metadata":{"id":"NEcCZ4bFtzgq","executionInfo":{"status":"ok","timestamp":1601896243052,"user_tz":-540,"elapsed":540,"user":{"displayName":"Seung min Yang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggh6p0khXlZ7IJRTGo-8JTqKaaHhMlpE2ET1kqtYQ=s64","userId":"01177916219728503153"}}},"source":["class Layer():\n","\n","  def __init__(self, W, b):\n","    self.W = W\n","    self.b = b\n","\n","    self.x = None\n","    self.origin_x_shape = None\n","\n","    self.dL_dW = None\n","    self.dL_db = None\n","\n","  def forward(self, x):\n","    self.origin_x_shape = x.shape\n","\n","    x = x.reshape(x.shape[0], -1)\n","    self.x = x\n","    out = np.dot(self.x, self.W) + self.b\n","\n","    return out\n","\n","  def backward(self, dout):\n","    dx = np.dot(dout, self.W.T)\n","    self.dL_dW = np.dot(self.x.T, dout)\n","    self.dL_db = np.sum(dout, axis=0)\n","    dx = dx.reshape(*self.origin_x_shape)\n","    return dx"],"execution_count":85,"outputs":[]},{"cell_type":"code","metadata":{"id":"0RXBVEMdvP9r","executionInfo":{"status":"ok","timestamp":1601896243715,"user_tz":-540,"elapsed":694,"user":{"displayName":"Seung min Yang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggh6p0khXlZ7IJRTGo-8JTqKaaHhMlpE2ET1kqtYQ=s64","userId":"01177916219728503153"}}},"source":["class Softmax():\n","\n","  def __init__(self):\n","    self.loss = None\n","    self.y = None\n","    self.t = None\n","\n","  def forward(self, x, t):\n","    self.t = t\n","    self.y =softmax(x)\n","    self.loss =  cross_entropy_error(self.y, self.t)\n","\n","    return self.loss\n","\n","  def backward(self, dout=1):\n","    batch_size = self.t.shape[0]\n","\n","    if self.t.size == self.y.size:\n","      dx = (self.y - self.t) / batch_size\n","    else:\n","      dx = self.y.copy()\n","      dx[np.arange(batch_sie), self.t] -= 1\n","      dx = dx / batch_size\n","    \n","    return dx\n"],"execution_count":86,"outputs":[]},{"cell_type":"code","metadata":{"id":"sX4I-bKfuRaq","executionInfo":{"status":"ok","timestamp":1601896244086,"user_tz":-540,"elapsed":526,"user":{"displayName":"Seung min Yang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggh6p0khXlZ7IJRTGo-8JTqKaaHhMlpE2ET1kqtYQ=s64","userId":"01177916219728503153"}}},"source":["class MyModel():\n","\n","  def __init__(self, input_size, hidden_size_list, output_size, activation ='relu'):\n","    self.input_size = input_size\n","    self.output_size = output_size\n","    self.hidden_size_list = hidden_size_list\n","    self.hidden_layer_num = len(hidden_size_list)\n","    self.params = {}\n","\n","    self.__init_weights(activation)\n","\n","    activation_layer = {'sigmoid': Sigmoid, 'relu':ReLU}\n","    self.layers = OrderedDict()\n","    for idx in range(1, self.hidden_layer_num + 1):\n","      self.layers['Layer' + str(idx)] = Layer(self.params['W' + str(idx)], self.params['b' + str(idx)])\n","      self.layers['Activation_function' + str(idx)] = activation_layer[activation]()\n","    \n","    idx = self.hidden_layer_num + 1\n","\n","    self.layers['Layer' + str(idx)] = Layer(self.params['W' + str(idx)], self.params['b' + str(idx)])\n","\n","    self.last_layer = Softmax()\n","\n","  def __init_weights(self, activation):\n","    weight_std = None\n","    all_size_list = [self.input_size] + self.hidden_size_list + [self.output_size]\n","    for idx in range(1, len(all_size_list)):\n","      if activation.lower() == 'relu':\n","        weight_std = np.sqrt(2.0 / self.input_size)\n","      elif activation.lower() == 'sigmoid':\n","        weight_std = np.sqrt(1.0 / self.input_size)\n","\n","      self.params['W' + str(idx)] = weight_std * np.random.randn(all_size_list[idx-1], all_size_list[idx])\n","      self.params['b' + str(idx)] = np.random.randn(all_size_list[idx])\n","\n","  def predict(self, x):\n","    for layer in self.layers.values():\n","      #print(layer)\n","      x = layer.forward(x)\n","\n","    return x\n","\n","  def loss(self, x, true_y):\n","    pred_y = self.predict(x)\n","\n","    return self.last_layer.forward(pred_y, true_y)\n","\n","  def accuracy(self, x, true_y):\n","    pred_y = self.predict(x)\n","    pred_y = np.argmax(pred_y, axis=1)\n","\n","    if true_y.ndim != 1:\n","      true_y = np.argmax(true_y, axis=1)\n","    \n","    accuracy = np.sum(pred_y == true_y) / float(x.shape[0])\n","    return accuracy\n","  \n","  def gradient(self, x, t):\n","    self.loss(x, t)\n","\n","    dout = 1\n","    dout  = self.last_layer.backward(dout)\n","\n","    layers = list(self.layers.values())\n","    layers.reverse()\n","    for layer in layers:\n","      dout = layer.backward(dout)\n","\n","    grads = {}\n","    for idx in range(1, self.hidden_layer_num + 2):\n","      grads['W' + str(idx)] = self.layers['Layer' + str(idx)].dL_dW\n","      grads['b' + str(idx)] = self.layers['Layer' + str(idx)].dL_db\n","\n","    return grads\n"],"execution_count":87,"outputs":[]},{"cell_type":"code","metadata":{"id":"Du5naLufxMvv","executionInfo":{"status":"ok","timestamp":1601896367879,"user_tz":-540,"elapsed":800,"user":{"displayName":"Seung min Yang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggh6p0khXlZ7IJRTGo-8JTqKaaHhMlpE2ET1kqtYQ=s64","userId":"01177916219728503153"}}},"source":["model = MyModel(14*14, [50, 32, 16], 10, 'relu')"],"execution_count":96,"outputs":[]},{"cell_type":"code","metadata":{"id":"Rb0HhW9x0mrN","executionInfo":{"status":"ok","timestamp":1601896367879,"user_tz":-540,"elapsed":537,"user":{"displayName":"Seung min Yang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggh6p0khXlZ7IJRTGo-8JTqKaaHhMlpE2ET1kqtYQ=s64","userId":"01177916219728503153"}}},"source":["train_loss_list = []\n","train_acc_list = []\n","test_acc_list = []"],"execution_count":97,"outputs":[]},{"cell_type":"code","metadata":{"id":"VV5PciwAxM6s","executionInfo":{"status":"ok","timestamp":1601896397044,"user_tz":-540,"elapsed":15156,"user":{"displayName":"Seung min Yang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggh6p0khXlZ7IJRTGo-8JTqKaaHhMlpE2ET1kqtYQ=s64","userId":"01177916219728503153"}},"outputId":"f4a8a06a-17b8-45be-8ff2-eb774362a182","colab":{"base_uri":"https://localhost:8080/","height":377}},"source":["for epoch in range(epochs):\n","  batch_mask = np.random.choice(train_size, batch_size)\n","  x_batch = X_train[batch_mask]\n","  y_batch = y_train[batch_mask]\n","\n","  grad = model.gradient(x_batch, y_batch)\n","\n","  for key in model.params.keys():\n","    model.params[key] -= learning_rate * grad[key]\n","\n","  loss = model.loss(x_batch, y_batch)\n","  train_loss_list.append(loss)\n","\n","  if epoch % 50 == 0:\n","    train_acc = model.accuracy(X_train,y_train)\n","    test_acc = model.accuracy(X_test, y_test)\n","    train_acc_list.append(train_acc)\n","    test_acc_list.append(test_acc)\n","    print(\"Epoch: {} Train Accuracy: {:.4f} Test Accuracy: {:.4f}\".format(epoch+1, train_acc, test_acc))"],"execution_count":99,"outputs":[{"output_type":"stream","text":["Epoch: 1 Train Accuracy: 0.8488 Test Accuracy: 0.8541\n","Epoch: 51 Train Accuracy: 0.8528 Test Accuracy: 0.8591\n","Epoch: 101 Train Accuracy: 0.8532 Test Accuracy: 0.8592\n","Epoch: 151 Train Accuracy: 0.8524 Test Accuracy: 0.8628\n","Epoch: 201 Train Accuracy: 0.8560 Test Accuracy: 0.8667\n","Epoch: 251 Train Accuracy: 0.8651 Test Accuracy: 0.8725\n","Epoch: 301 Train Accuracy: 0.8650 Test Accuracy: 0.8714\n","Epoch: 351 Train Accuracy: 0.8711 Test Accuracy: 0.8744\n","Epoch: 401 Train Accuracy: 0.8693 Test Accuracy: 0.8730\n","Epoch: 451 Train Accuracy: 0.8707 Test Accuracy: 0.8752\n","Epoch: 501 Train Accuracy: 0.8762 Test Accuracy: 0.8818\n","Epoch: 551 Train Accuracy: 0.8787 Test Accuracy: 0.8813\n","Epoch: 601 Train Accuracy: 0.8832 Test Accuracy: 0.8863\n","Epoch: 651 Train Accuracy: 0.8821 Test Accuracy: 0.8865\n","Epoch: 701 Train Accuracy: 0.8791 Test Accuracy: 0.8804\n","Epoch: 751 Train Accuracy: 0.8885 Test Accuracy: 0.8917\n","Epoch: 801 Train Accuracy: 0.8856 Test Accuracy: 0.8906\n","Epoch: 851 Train Accuracy: 0.8857 Test Accuracy: 0.8860\n","Epoch: 901 Train Accuracy: 0.8909 Test Accuracy: 0.8964\n","Epoch: 951 Train Accuracy: 0.8960 Test Accuracy: 0.8988\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"8l5b3UNddv2F"},"source":[""],"execution_count":null,"outputs":[]}]}